{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU dspy-ai nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rchrdgwr/anaconda3/envs/llmops-course/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from dspy import LM\n",
    "\n",
    "llm = LM(model='openai/gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at manually creating signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is England?\n",
      "Predicted Answer 1: United Kingdom\n",
      "Predicted Answer 2: Preheat oven, mix ingredients, bake.\n"
     ]
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\", prefix=\"Question's Answer:\")\n",
    "\n",
    "predictor = dspy.Predict(BasicQA)\n",
    "question = \"Where is England?\"\n",
    "pred = predictor(question=question)\n",
    "pred_2 = predictor(question=\"How do I bake a cake?\")\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Predicted Answer 1: {pred.answer}\")\n",
    "print(f\"Predicted Answer 2: {pred_2.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predict(BasicQA(question -> answer\n",
       "    instructions='Answer questions with short factoid answers.'\n",
       "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', 'prefix': \"Question's Answer:\", '__dspy_field_type': 'output'})\n",
       "))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is England?\n",
      "Predicted Answer 1: United Kingdom\n",
      "Predicted Answer 2: Preheat oven, mix ingredients, bake.\n",
      "Question: <bound method Prediction.from_completions of <class 'dspy.primitives.prediction.Prediction'>>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Predicted Answer 1: {pred.answer}\")\n",
    "print(f\"Predicted Answer 2: {pred_2.answer}\")\n",
    "print(f\"Question: {pred.from_completions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypedPredictor(BasicQA(question -> answer\n",
       "    instructions='Answer questions with short factoid answers.'\n",
       "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', 'prefix': \"Question's Answer:\", '__dspy_field_type': 'output'})\n",
       "))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.functional import TypedPredictor\n",
    "predictor_2 = TypedPredictor(BasicQA)\n",
    "predictor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `answer` (str): often between 1 and 5 words\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Answer questions with short factoid answers.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "How do I bake a cake?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `answer`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "Preheat oven, mix ingredients, bake.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Example({'sentence': 'A sentence', 'rating': 'A rating'}) (input_keys={'sentence'})\n",
      "['__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_demos', '_input_keys', '_store', 'copy', 'get', 'inputs', 'items', 'keys', 'labels', 'toDict', 'values', 'with_inputs', 'without']\n",
      "Sentence: A sentence\n",
      "Rating: A rating\n",
      "---\n",
      "Example 2\n",
      "Example({'question': 'How big is a cow?', 'relative_size': '17 breadboxes'}) (input_keys={'question'})\n"
     ]
    }
   ],
   "source": [
    "from dspy import Example\n",
    "\n",
    "my_example_1 = Example(sentence=\"A sentence\", rating=\"A rating\").with_inputs(\"sentence\")\n",
    "print(\"Example 1\")\n",
    "print(my_example_1)\n",
    "print(dir(my_example_1))\n",
    "print(f\"Sentence: {my_example_1.sentence}\")\n",
    "print(f\"Rating: {my_example_1.rating}\")\n",
    "print(\"---\")\n",
    "my_example_2 = Example(question=\"How big is a cow?\", relative_size=\"17 breadboxes\").with_inputs(\"question\")\n",
    "print(\"Example 2\")\n",
    "print(my_example_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
