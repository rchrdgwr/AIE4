{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNF2FTJcYP7u"
      },
      "source": [
        "# DSPy - Advanced Prompt Engineering\n",
        "\n",
        "1. Breakout Room #1:\n",
        "  - Task 1: Dependencies\n",
        "  - Task 2: Loading Our Model\n",
        "  - Task 3: Loading Our Data\n",
        "  - Task 4: Setting Our Signature\n",
        "  - Task 5: Creating a Predictor\n",
        "  - Task 6: Making a Chain, I mean...Module\n",
        "  - Task 7: Evaluate\n",
        "  - Task 8: Program Optimization\n",
        "2. Breakout Room #2:\n",
        "  - Task 1: Defining Appliation\n",
        "  - Task 2: Hyper-Parameters and Data\n",
        "  - Task 3: Signature And Module Creation\n",
        "  - Task 4: Evaluating Our LongFormQA Module\n",
        "  - Task 5: Adding Assertions\n",
        "\n",
        "---\n",
        "\n",
        "In the following notebook, we'll explore an introduction to DSPy and what it can do in just a few lines of code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8VnLGF_33VI"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmhp5fwk2nvT"
      },
      "source": [
        "## Task 1: Dependencies\n",
        "\n",
        "We'll start by installing DSPy, `nltk` (for later) and including our OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeoJU4iE3AWt",
        "outputId": "ec75ddd4-470e-4f5b-9237-8535e6356b05"
      },
      "outputs": [],
      "source": [
        "!pip install -qU dspy-ai nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrDi65cdY0pa"
      },
      "source": [
        "DSPy can leverage OpenAI's models under the hood, and still provide an advantage - in order to do so, however, we'll need to provide an OpenAI API Key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lPWT4vL8zFd",
        "outputId": "eb053089-dcf3-40e1-883f-6f69ff87d18d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW3W8ogDZJS_"
      },
      "source": [
        "## Task 2: Loading Our Model\n",
        "\n",
        "Now we can setup our OpenAI language model - which we'll use through the remaining cells in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VJAy8_hw8rUu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rchrdgwr/anaconda3/envs/llmops-course/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
            "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
            "* 'smart_union' has been removed\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "from dspy import LM\n",
        "\n",
        "llm = LM(model='openai/gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONjD_6hKZPsD"
      },
      "source": [
        "Similar to other libraries, we can call the LLM directly with a string to get a response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlwRrI1UZOFc",
        "outputId": "7c359dbf-dd63-44a1-f43f-f2a19ec632e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The square root of pi is approximately 1.77245385091.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"What is the square root of pi?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I would rate the phrase \"This is top tier\" a 3 out of 4. It conveys a sense of high quality and excellence, making it a strong and impactful statement.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"On a scale of 0-4 how dope is the phrase 'This is top tier.'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAO_nkG_ZVVV"
      },
      "source": [
        "We'll also set our `setting.configure` with our OpenAI model in the `lm` (Language Model) field for a default LM to use in case we don't specify which LM we'd like to use when calling our DSPy `Predictors`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "feM8E46m9Gna"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "\n",
        "dspy.settings.configure(lm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5H-q4WdZhc3"
      },
      "source": [
        "## Task 3: Load Our Data\n",
        "\n",
        "We're going to be using a dataset that provides a number of example sentences, along with a rating that indicates their \"dopeness\" level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n__G5nrU-Epz"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"llm-wizard/dope_or_nope_v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMgZxUByaz68"
      },
      "source": [
        "We have a total of 99 rows of data, and will be splitting that into a `trainset` and a `valset` - for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMBCVzwhDKJr",
        "outputId": "c90f89e1-eef9-4ceb-fbe1-1492d2b462ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Sentence', 'Rating', 'Fire Emojis'],\n",
              "        num_rows: 99\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwyoqDkvcBxr"
      },
      "source": [
        "Due to the nature of the dataset, we'll need to shuffle our dataset to ensure our labels are not clumped up, and our `valset` is remotely representative to our `trainset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RecukH0rVkNY"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle(seed=42)  # randomly rearranges dataset - uses a random see for reproducability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrr-xSbtcPBK"
      },
      "source": [
        "We'll move our `Dataset` into the expected format in DSPy which is the [`Example`](https://dspy-docs.vercel.app/docs/deep-dive/data-handling/examples)!\n",
        "\n",
        "\n",
        "Our examples will have two keys:\n",
        "\n",
        "- `sentence`, our input sentence to be rated\n",
        "- `rating`, our rating label\n",
        "\n",
        "We'll specify our input as `sentence` to properly leverage the DSPy framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ARkkb_CnBT",
        "outputId": "c4662436-8ab1-4381-dd3a-82867b711ddc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dspy import Example\n",
        "\n",
        "trainset = []\n",
        "\n",
        "for row in dataset[\"train\"].select(range(0,len(dataset[\"train\"])-10)):\n",
        "  trainset.append(Example(sentence=row[\"Sentence\"], rating=row[\"Rating\"]).with_inputs(\"sentence\"))\n",
        "\n",
        "len(trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZC2yAnqc31Q"
      },
      "source": [
        "We'll repeat the same process for our `valset` as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTDPZJUZD_hM",
        "outputId": "1e9ddeda-6813-4e8f-89e8-05ffceee10d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Sentence': 'This is top tier.', 'Rating': 4, 'Fire Emojis': 'üî•üî•üî•üî•'}\n",
            "{'Sentence': 'Big mood.', 'Rating': 3, 'Fire Emojis': 'üî•üî•üî•'}\n",
            "{'Sentence': 'The presentation was outstanding.', 'Rating': 1, 'Fire Emojis': 'üî•'}\n",
            "{'Sentence': \"I'm living my best life.\", 'Rating': 4, 'Fire Emojis': 'üî•üî•üî•üî•'}\n",
            "{'Sentence': \"Sksksksk, that's hilarious.\", 'Rating': 3, 'Fire Emojis': 'üî•üî•üî•'}\n",
            "{'Sentence': 'The report is comprehensive.', 'Rating': 1, 'Fire Emojis': 'üî•'}\n",
            "{'Sentence': 'This is next level.', 'Rating': 4, 'Fire Emojis': 'üî•üî•üî•üî•'}\n",
            "{'Sentence': 'The meeting was productive.', 'Rating': 1, 'Fire Emojis': 'üî•'}\n",
            "{'Sentence': 'The analysis was insightful.', 'Rating': 1, 'Fire Emojis': 'üî•'}\n",
            "{'Sentence': 'I stan a legend.', 'Rating': 3, 'Fire Emojis': 'üî•üî•üî•'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valset = []\n",
        "\n",
        "for row in dataset[\"train\"].select(range(len(trainset),len(dataset[\"train\"]))):\n",
        "  print(row)\n",
        "  valset.append(Example(sentence=row[\"Sentence\"], rating=row[\"Rating\"]).with_inputs(\"sentence\"))\n",
        "\n",
        "len(valset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKKim9uRc8Q0"
      },
      "source": [
        "Let's take a peek at an example from our `trainset` and `valset`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVgP0ctkEJC9",
        "outputId": "18a13416-4ed2-4144-bacb-cce2e21f7e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: The results were satisfactory.\n",
            "Rating: 0\n"
          ]
        }
      ],
      "source": [
        "train_example = trainset[0]\n",
        "print(f\"Sentence: {train_example.sentence}\")\n",
        "print(f\"Rating: {train_example.rating}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHFDjOT9EUip",
        "outputId": "3744d91b-6791-4935-ab0c-30f805ababcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: This is top tier.\n",
            "Rating: 4\n"
          ]
        }
      ],
      "source": [
        "valset_example = valset[0]\n",
        "print(f\"Sentence: {valset_example.sentence}\")\n",
        "print(f\"Rating: {valset_example.rating}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjjPIJsdAYs"
      },
      "source": [
        "## Task 4: Setting Our Signature\n",
        "\n",
        "The first foundational unit in DSPy is the `Signature`.\n",
        "\n",
        "In a sense, a `Signature` can be thought of as both a prompt, as well as metadata about that prompt.\n",
        "\n",
        "Going beyond just a simple `SystemMessage`, as seen in other frameworks, the `Signature` helps DSPy validate datatypes, create examples, and more.\n",
        "\n",
        "> NOTE: DSPy's [documentation](https://dspy-docs.vercel.app/docs/deep-dive/signature/understanding-signatures#what-is-a-signature) goes into more detail about what exactly a `Signature` is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WcshNXosEaRb"
      },
      "outputs": [],
      "source": [
        "from dspy import Signature, InputField, OutputField\n",
        "\n",
        "class DopeOrNopeSignature(Signature):\n",
        "  \"\"\"Rate a sentence from 0 to 4 on a dopeness scale\"\"\"\n",
        "  sentence: str = InputField()\n",
        "  rating: int = OutputField()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5BnXK3VdnSL"
      },
      "source": [
        "## Task 5: Creating a Predictor\n",
        "\n",
        "Now that we have our `Signature`, we can build a `Predictor` that leverages it.\n",
        "\n",
        "A `Predictor`, in the simplest terms, is what calls the LLM using our signature. Importantly, the `Predictor` knows how to leverage our signature to call the LLM. From DSPy's documentation, one of the most interesting parts of a `Predictor` is that it can *learn* to become better at the desired task!\n",
        "\n",
        "Let's take a look at our `TypedPredictor` below to see more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xxsLox0KEtwk"
      },
      "outputs": [],
      "source": [
        "from dspy.functional import TypedPredictor\n",
        "\n",
        "predict_dopeness = TypedPredictor(DopeOrNopeSignature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKjZPqJCeeGs",
        "outputId": "7305bfe1-4414-46bb-bcac-4f8566022317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TypedPredictor(DopeOrNopeSignature(sentence -> rating\n",
              "    instructions='Rate a sentence from 0 to 4 on a dopeness scale'\n",
              "    sentence = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Sentence:', 'desc': '${sentence}'})\n",
              "    rating = Field(annotation=int required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Rating:', 'desc': '${rating}'})\n",
              "))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_dopeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUjXc2BIE_as",
        "outputId": "15c937b9-f0ef-4c3c-8aef-f09e73ee8e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: This is top tier.\n",
            "Prediction: Prediction(\n",
            "    rating=4\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "dopeness_prediction = predict_dopeness(sentence=valset_example.sentence)\n",
        "print(f\"Sentence: {valset_example.sentence}\")\n",
        "print(f\"Prediction: {dopeness_prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw6qrDP7gbf1"
      },
      "source": [
        "We can, at any time, check our LLMs outputs through the `inspect_history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncjnowmCHGd0",
        "outputId": "f3ecc6a9-db92-45a8-eef4-b9b68928d09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `sentence` (str)\n",
            "\n",
            "Your output fields are:\n",
            "1. `rating` (int): ${rating} (Respond with a single int value)\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "{sentence}\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "{rating}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        Rate a sentence from 0 to 4 on a dopeness scale\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This is top tier.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## rating ## ]]\n",
            "4\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "llm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTiQ2g3afO8k"
      },
      "source": [
        "Notice how, without our input - the `TypedPredictor` has included format instructions to the LLM to help ensure our returned data resembles what we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuuQ1GxNffdm"
      },
      "source": [
        "Let's look at another example of a `Predictor` - this time with Chain of Thought.\n",
        "\n",
        "In order to use this - we don't have to do anything with our `Signature`! We can leave it exactly as is - and allow the `Predictor` to adapt to it.\n",
        "\n",
        "> NOTE: We won't be using this predictor going forward - this is just to showcase the ease of using another `Predictor` with a `Signature`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CcRQk4uQHImC"
      },
      "outputs": [],
      "source": [
        "from dspy.functional import TypedChainOfThought\n",
        "\n",
        "generate_rating_with_chain_of_thought = TypedChainOfThought(DopeOrNopeSignature)\n",
        "\n",
        "rating_prediction = generate_rating_with_chain_of_thought(sentence=valset_example.sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZf2PNb8HYaT",
        "outputId": "e4fb363d-a7dd-41c0-eb2d-dae82939ee07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: This is top tier.\n",
            "Reasoning: I would rate this sentence as a 4 because it conveys a high level of excellence or superiority.\n",
            "Ground Truth Label: 4\n",
            "Prediction: 4\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sentence: {valset_example.sentence}\")\n",
        "print(f\"Reasoning: {rating_prediction.reasoning}\")\n",
        "print(f\"Ground Truth Label: {valset_example.rating}\")\n",
        "print(f\"Prediction: {rating_prediction.rating}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miii9xQxgAzm"
      },
      "source": [
        "We can, again, check our LLM's history to see what the actual prompt/response is.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMxOlK65VzCZ",
        "outputId": "ba589f03-e711-4574-f19e-069a0904193d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `sentence` (str)\n",
            "\n",
            "Your output fields are:\n",
            "1. `reasoning` (str): ${produce the rating}. We ...\n",
            "2. `rating` (int): ${rating} (Respond with a single int value)\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "{sentence}\n",
            "\n",
            "[[ ## reasoning ## ]]\n",
            "{reasoning}\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "{rating}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        Rate a sentence from 0 to 4 on a dopeness scale\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This is top tier.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `reasoning`, then `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## reasoning ## ]]\n",
            "I would rate this sentence as a 4 because it conveys a high level of excellence or superiority. \n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "llm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7U3yeCsg3B2"
      },
      "source": [
        "## Task 6: Making a Chain, I mean...Module.\n",
        "\n",
        "Now that we have our `TypedPredictor`, we can create a `Module`!\n",
        "\n",
        "A `Module` is useful because it allows us to interact with the `Predictor` and `Signature` in a way that DSPy can leverage for optimization.\n",
        "\n",
        "The helps the DSPy framework determine paths through your program - and helps during the `compilation` or optimisation steps (formerly `teleprompting`).\n",
        "\n",
        "> NOTE: You might notice this looks strikingly familiar to PyTorch, and this is by design!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H6GoyWyUJkl6"
      },
      "outputs": [],
      "source": [
        "from dspy import Module, Prediction\n",
        "\n",
        "class DopeOrNopeStudent(Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.generate_rating = TypedPredictor(DopeOrNopeSignature)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    prediction = self.generate_rating(sentence=sentence)\n",
        "    return Prediction(rating=prediction.rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS2pf8tjh7lH"
      },
      "source": [
        "## Task 7: Evaluate\n",
        "\n",
        "As with any good framework, DSPy has the ability to `Evaluate` - we can leverage this to determine how our current DSPy \"program\" (our `Module` in this case) operates.\n",
        "\n",
        "> NOTE: DSPy's \"program\" could be loosely related to a \"chain\" from the popular LLM Framework LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "C9o5461qMKyt",
        "outputId": "7237d853-bdc1-4e48-c084-81d49e110d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 5 / 10  (50.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 260.81it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_15adf th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_15adf td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_15adf_row0_col0, #T_15adf_row0_col1, #T_15adf_row0_col2, #T_15adf_row0_col3, #T_15adf_row1_col0, #T_15adf_row1_col1, #T_15adf_row1_col2, #T_15adf_row1_col3, #T_15adf_row2_col0, #T_15adf_row2_col1, #T_15adf_row2_col2, #T_15adf_row2_col3, #T_15adf_row3_col0, #T_15adf_row3_col1, #T_15adf_row3_col2, #T_15adf_row3_col3, #T_15adf_row4_col0, #T_15adf_row4_col1, #T_15adf_row4_col2, #T_15adf_row4_col3, #T_15adf_row5_col0, #T_15adf_row5_col1, #T_15adf_row5_col2, #T_15adf_row5_col3, #T_15adf_row6_col0, #T_15adf_row6_col1, #T_15adf_row6_col2, #T_15adf_row6_col3, #T_15adf_row7_col0, #T_15adf_row7_col1, #T_15adf_row7_col2, #T_15adf_row7_col3, #T_15adf_row8_col0, #T_15adf_row8_col1, #T_15adf_row8_col2, #T_15adf_row8_col3, #T_15adf_row9_col0, #T_15adf_row9_col1, #T_15adf_row9_col2, #T_15adf_row9_col3 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_15adf\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_15adf_level0_col0\" class=\"col_heading level0 col0\" >sentence</th>\n",
              "      <th id=\"T_15adf_level0_col1\" class=\"col_heading level0 col1\" >example_rating</th>\n",
              "      <th id=\"T_15adf_level0_col2\" class=\"col_heading level0 col2\" >pred_rating</th>\n",
              "      <th id=\"T_15adf_level0_col3\" class=\"col_heading level0 col3\" >exact_match_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_15adf_row0_col0\" class=\"data row0 col0\" >This is top tier.</td>\n",
              "      <td id=\"T_15adf_row0_col1\" class=\"data row0 col1\" >4</td>\n",
              "      <td id=\"T_15adf_row0_col2\" class=\"data row0 col2\" >4</td>\n",
              "      <td id=\"T_15adf_row0_col3\" class=\"data row0 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_15adf_row1_col0\" class=\"data row1 col0\" >Big mood.</td>\n",
              "      <td id=\"T_15adf_row1_col1\" class=\"data row1 col1\" >3</td>\n",
              "      <td id=\"T_15adf_row1_col2\" class=\"data row1 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row1_col3\" class=\"data row1 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_15adf_row2_col0\" class=\"data row2 col0\" >The presentation was outstanding.</td>\n",
              "      <td id=\"T_15adf_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "      <td id=\"T_15adf_row2_col2\" class=\"data row2 col2\" >4</td>\n",
              "      <td id=\"T_15adf_row2_col3\" class=\"data row2 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_15adf_row3_col0\" class=\"data row3 col0\" >I'm living my best life.</td>\n",
              "      <td id=\"T_15adf_row3_col1\" class=\"data row3 col1\" >4</td>\n",
              "      <td id=\"T_15adf_row3_col2\" class=\"data row3 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row3_col3\" class=\"data row3 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_15adf_row4_col0\" class=\"data row4 col0\" >Sksksksk, that's hilarious.</td>\n",
              "      <td id=\"T_15adf_row4_col1\" class=\"data row4 col1\" >3</td>\n",
              "      <td id=\"T_15adf_row4_col2\" class=\"data row4 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row4_col3\" class=\"data row4 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_15adf_row5_col0\" class=\"data row5 col0\" >The report is comprehensive.</td>\n",
              "      <td id=\"T_15adf_row5_col1\" class=\"data row5 col1\" >1</td>\n",
              "      <td id=\"T_15adf_row5_col2\" class=\"data row5 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row5_col3\" class=\"data row5 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_15adf_row6_col0\" class=\"data row6 col0\" >This is next level.</td>\n",
              "      <td id=\"T_15adf_row6_col1\" class=\"data row6 col1\" >4</td>\n",
              "      <td id=\"T_15adf_row6_col2\" class=\"data row6 col2\" >4</td>\n",
              "      <td id=\"T_15adf_row6_col3\" class=\"data row6 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_15adf_row7_col0\" class=\"data row7 col0\" >The meeting was productive.</td>\n",
              "      <td id=\"T_15adf_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "      <td id=\"T_15adf_row7_col2\" class=\"data row7 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row7_col3\" class=\"data row7 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_15adf_row8_col0\" class=\"data row8 col0\" >The analysis was insightful.</td>\n",
              "      <td id=\"T_15adf_row8_col1\" class=\"data row8 col1\" >1</td>\n",
              "      <td id=\"T_15adf_row8_col2\" class=\"data row8 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row8_col3\" class=\"data row8 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_15adf_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_15adf_row9_col0\" class=\"data row9 col0\" >I stan a legend.</td>\n",
              "      <td id=\"T_15adf_row9_col1\" class=\"data row9 col1\" >3</td>\n",
              "      <td id=\"T_15adf_row9_col2\" class=\"data row9 col2\" >3</td>\n",
              "      <td id=\"T_15adf_row9_col3\" class=\"data row9 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f50c5e01a50>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dspy.evaluate.evaluate import Evaluate\n",
        "\n",
        "evaluate_fewshot = Evaluate(devset=valset, num_threads=1, display_progress=True, display_table=10)\n",
        "\n",
        "def exact_match_metric(answer, pred, trace=None):\n",
        "  return answer.rating == pred.rating\n",
        "\n",
        "evaluate_fewshot(DopeOrNopeStudent(), metric=exact_match_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw030e6I4UEo"
      },
      "source": [
        "#### ‚ùìQuestion #1:\n",
        "\n",
        "Does DSPy lend itself to more complex less exactly defined evaluations? Provide reasoning for your answer.\n",
        "\n",
        "#### ! Answer #1:\n",
        "\n",
        "I believe DSPy is designed to handle complex less exactly defined evaluations.\n",
        "\n",
        "DSPy supports the following which helps handle complex evaluations:\n",
        "- Modularity - can break complex tasks into simpler components. Can create complex Modules from simpler Modules\n",
        "- Flexibility - can define custom inputs and outputs, data flow, and evaluation\n",
        "- Self-optimization - based on performance feedback\n",
        "- Choice - offers numerous different options that can easily be plugged in without changing the fundamental process using the Examples, Signatures, and Modules, and the different TypedPredictors\n",
        "- Customization - can create custom evaluators, \n",
        "\n",
        "Since DSPy separates the program flow from the parameters controling the behavior of a module or model through weights or configurations, this allows focus on the goals of the program and not worry about the details of parameter tuning. This is helpful in handling complex evaluations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIK6OdQFiUww"
      },
      "source": [
        "## Task 8: Program Optimization (the Artist Formerly Known as Teleprompting)\n",
        "\n",
        "Optimization is the crux of the DSPy framework - it is what allows it to operate at a level beyond traditional prompt engineering.\n",
        "\n",
        "At a high level, optimisation is a way for the DSPy framework to take the program, a training set, and a metric - and make changes/tweaks to our program to improve our metrics on our dataset.\n",
        "\n",
        "Let's get started with the `LabeledFewShot` optimizer.\n",
        "\n",
        "The `LabeledFewShot` optimizer very simply provides a sample of the `trainset` as few-shot examples!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wBq1Xs-CHphS"
      },
      "outputs": [],
      "source": [
        "from dspy.teleprompt import LabeledFewShot\n",
        "\n",
        "labeled_fewshot_optimizer = LabeledFewShot(k=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdtrS7hXjHzv"
      },
      "source": [
        "Once we define our optimizer, we can compile our program!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eVv4aK2QJD3v"
      },
      "outputs": [],
      "source": [
        "compiled_dspy = labeled_fewshot_optimizer.compile(student=DopeOrNopeStudent(), trainset=trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k_KhbL_jMXK"
      },
      "source": [
        "Let's evaluate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "oxl_zZ51JQRc",
        "outputId": "b23db3fe-4902-4399-d0b7-e93dbbcc875a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 3 / 10  (30.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 198.13it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_85df9 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_85df9 td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_85df9_row0_col0, #T_85df9_row0_col1, #T_85df9_row0_col2, #T_85df9_row0_col3, #T_85df9_row1_col0, #T_85df9_row1_col1, #T_85df9_row1_col2, #T_85df9_row1_col3, #T_85df9_row2_col0, #T_85df9_row2_col1, #T_85df9_row2_col2, #T_85df9_row2_col3, #T_85df9_row3_col0, #T_85df9_row3_col1, #T_85df9_row3_col2, #T_85df9_row3_col3, #T_85df9_row4_col0, #T_85df9_row4_col1, #T_85df9_row4_col2, #T_85df9_row4_col3, #T_85df9_row5_col0, #T_85df9_row5_col1, #T_85df9_row5_col2, #T_85df9_row5_col3, #T_85df9_row6_col0, #T_85df9_row6_col1, #T_85df9_row6_col2, #T_85df9_row6_col3, #T_85df9_row7_col0, #T_85df9_row7_col1, #T_85df9_row7_col2, #T_85df9_row7_col3, #T_85df9_row8_col0, #T_85df9_row8_col1, #T_85df9_row8_col2, #T_85df9_row8_col3, #T_85df9_row9_col0, #T_85df9_row9_col1, #T_85df9_row9_col2, #T_85df9_row9_col3 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_85df9\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_85df9_level0_col0\" class=\"col_heading level0 col0\" >sentence</th>\n",
              "      <th id=\"T_85df9_level0_col1\" class=\"col_heading level0 col1\" >example_rating</th>\n",
              "      <th id=\"T_85df9_level0_col2\" class=\"col_heading level0 col2\" >pred_rating</th>\n",
              "      <th id=\"T_85df9_level0_col3\" class=\"col_heading level0 col3\" >exact_match_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_85df9_row0_col0\" class=\"data row0 col0\" >This is top tier.</td>\n",
              "      <td id=\"T_85df9_row0_col1\" class=\"data row0 col1\" >4</td>\n",
              "      <td id=\"T_85df9_row0_col2\" class=\"data row0 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row0_col3\" class=\"data row0 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_85df9_row1_col0\" class=\"data row1 col0\" >Big mood.</td>\n",
              "      <td id=\"T_85df9_row1_col1\" class=\"data row1 col1\" >3</td>\n",
              "      <td id=\"T_85df9_row1_col2\" class=\"data row1 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row1_col3\" class=\"data row1 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_85df9_row2_col0\" class=\"data row2 col0\" >The presentation was outstanding.</td>\n",
              "      <td id=\"T_85df9_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "      <td id=\"T_85df9_row2_col2\" class=\"data row2 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row2_col3\" class=\"data row2 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_85df9_row3_col0\" class=\"data row3 col0\" >I'm living my best life.</td>\n",
              "      <td id=\"T_85df9_row3_col1\" class=\"data row3 col1\" >4</td>\n",
              "      <td id=\"T_85df9_row3_col2\" class=\"data row3 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row3_col3\" class=\"data row3 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_85df9_row4_col0\" class=\"data row4 col0\" >Sksksksk, that's hilarious.</td>\n",
              "      <td id=\"T_85df9_row4_col1\" class=\"data row4 col1\" >3</td>\n",
              "      <td id=\"T_85df9_row4_col2\" class=\"data row4 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row4_col3\" class=\"data row4 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_85df9_row5_col0\" class=\"data row5 col0\" >The report is comprehensive.</td>\n",
              "      <td id=\"T_85df9_row5_col1\" class=\"data row5 col1\" >1</td>\n",
              "      <td id=\"T_85df9_row5_col2\" class=\"data row5 col2\" >2</td>\n",
              "      <td id=\"T_85df9_row5_col3\" class=\"data row5 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_85df9_row6_col0\" class=\"data row6 col0\" >This is next level.</td>\n",
              "      <td id=\"T_85df9_row6_col1\" class=\"data row6 col1\" >4</td>\n",
              "      <td id=\"T_85df9_row6_col2\" class=\"data row6 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row6_col3\" class=\"data row6 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_85df9_row7_col0\" class=\"data row7 col0\" >The meeting was productive.</td>\n",
              "      <td id=\"T_85df9_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "      <td id=\"T_85df9_row7_col2\" class=\"data row7 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row7_col3\" class=\"data row7 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_85df9_row8_col0\" class=\"data row8 col0\" >The analysis was insightful.</td>\n",
              "      <td id=\"T_85df9_row8_col1\" class=\"data row8 col1\" >1</td>\n",
              "      <td id=\"T_85df9_row8_col2\" class=\"data row8 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row8_col3\" class=\"data row8 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_85df9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_85df9_row9_col0\" class=\"data row9 col0\" >I stan a legend.</td>\n",
              "      <td id=\"T_85df9_row9_col1\" class=\"data row9 col1\" >3</td>\n",
              "      <td id=\"T_85df9_row9_col2\" class=\"data row9 col2\" >3</td>\n",
              "      <td id=\"T_85df9_row9_col3\" class=\"data row9 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f50c5ad5bd0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "30.0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_fewshot(compiled_dspy, metric=exact_match_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htpDiJLcjOOI"
      },
      "source": [
        "As you can see - with no effort at all - we can improve our performance on our `valset`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not sure what happened here. This is worse than the previous evaluation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyf5baq0jU1Z"
      },
      "source": [
        "Let's try another optimizer - this time: [`BootstrapFewShot`](https://dspy-docs.vercel.app/docs/deep-dive/teleprompter/bootstrap-fewshot).\n",
        "\n",
        "The key thing to note is that this optimizer works with even very few examples - by way of generating new examples by the LLMs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPx1wKpAUKBx",
        "outputId": "72691991-d2b1-4c2e-c064-2f62e79f6ba5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|‚ñå         | 5/89 [00:00<00:00, 252.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 6 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "optimizer = BootstrapFewShot(metric=exact_match_metric, max_bootstrapped_demos=4, max_labeled_demos=12)\n",
        "\n",
        "compiled_dspy_BOOTSTRAP = optimizer.compile(student=DopeOrNopeStudent(), trainset=trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `sentence` (str)\n",
            "\n",
            "Your output fields are:\n",
            "1. `rating` (int): ${rating} (Respond with a single int value)\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "{sentence}\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "{rating}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        Rate a sentence from 0 to 4 on a dopeness scale\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The approval was granted.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I admire your dedication.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "Too good to be true.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The software was updated.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The project was completed successfully.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The team performed exceptionally.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The methodology was sound.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This is such a vibe.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "Your feedback is valuable.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The campaign was well-received.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I will follow up accordingly.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This is such a flex.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This is a whole mood.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "llm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'prompt': None,\n",
              " 'messages': [{'role': 'system',\n",
              "   'content': 'Your input fields are:\\n1. `sentence` (str)\\n\\nYour output fields are:\\n1. `rating` (int): ${rating} (Respond with a single int value)\\n\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## sentence ## ]]\\n{sentence}\\n\\n[[ ## rating ## ]]\\n{rating}\\n\\n[[ ## completed ## ]]\\n\\nIn adhering to this structure, your objective is: \\n        Rate a sentence from 0 to 4 on a dopeness scale'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThe approval was granted.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nI admire your dedication.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nToo good to be true.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n4\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThe software was updated.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThe project was completed successfully.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThe team performed exceptionally.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThe methodology was sound.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThis is such a vibe.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n4\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nYour feedback is valuable.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThe campaign was well-received.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nI will follow up accordingly.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n1\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': '[[ ## sentence ## ]]\\nThis is such a flex.\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '[[ ## rating ## ]]\\n4\\n\\n[[ ## completed ## ]]'},\n",
              "  {'role': 'user',\n",
              "   'content': \"[[ ## sentence ## ]]\\nI'm shook!\\n\\nRespond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\"}],\n",
              " 'kwargs': {'temperature': 0.0, 'max_tokens': 1000},\n",
              " 'response': ModelResponse(id='chatcmpl-ABa3YuWHuAM4SmRcZWKOlRDSONX8C', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## rating ## ]]\\n4\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None))], created=1727323572, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=12, prompt_tokens=803, total_tokens=815, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)), service_tier=None),\n",
              " 'outputs': ['[[ ## rating ## ]]\\n4\\n\\n[[ ## completed ## ]]'],\n",
              " 'usage': {'completion_tokens': 12,\n",
              "  'prompt_tokens': 803,\n",
              "  'total_tokens': 815,\n",
              "  'completion_tokens_details': CompletionTokensDetails(reasoning_tokens=0)},\n",
              " 'cost': None}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(llm.history))\n",
        "llm.history[len(llm.history)-2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBO22kS42TLi"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Outline how `BootstrapFewShot` works \"under the hood\" in natural language or create a diagram of the workflow.\n",
        "\n",
        "\n",
        "### Activity #1:\n",
        "Basic flow is as follows:\n",
        "- Create the signature defining the inputs and outputs\n",
        "- Prepare the training dataset with one or more Example objects containing data conforming to the Signature\n",
        "- Create a Module that defines the Predictor based on the Signature as well as the forward() function that defines input -> output process\n",
        "- Create a metric function based on the input and output\n",
        "- Set up the parameters for number of bootstrapped demonstrations, number of labeled demonstrations and the number of bootstrap rounds\n",
        "- Call the compile function which:\n",
        "    - Calls the predictor defined in the module - this calls the forward(method)\n",
        "    - The forward() method sets up the prompt for the LLM using the signature, the LM parameters and the few shot examples passed\n",
        "    - The prompt is sent to the LLM and returns the prediction\n",
        "    - The bootstrap process creates a number of new examples through the LLM based off the examples passed\n",
        "    - These examples are used to send prompts to the LLM, the response to which are evaluated using the metric algorithm\n",
        "    - The module parameters and prompt are tweaked in order to improve the metric performance\n",
        "    - This is repeated a number of times based on the max_rounds\n",
        "    - The end result is a more performant, compiled version of the original module\n",
        "\n",
        "![dspy floe](images/dspy.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsF13taMo6dm"
      },
      "source": [
        "Let's finally evaluate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "lFwORTZbUcwG",
        "outputId": "9eddab79-f222-4ac3-ad43-02c4076f4d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 8 / 10  (80.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 101.39it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_26b47 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_26b47 td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_26b47_row0_col0, #T_26b47_row0_col1, #T_26b47_row0_col2, #T_26b47_row0_col3, #T_26b47_row1_col0, #T_26b47_row1_col1, #T_26b47_row1_col2, #T_26b47_row1_col3, #T_26b47_row2_col0, #T_26b47_row2_col1, #T_26b47_row2_col2, #T_26b47_row2_col3, #T_26b47_row3_col0, #T_26b47_row3_col1, #T_26b47_row3_col2, #T_26b47_row3_col3, #T_26b47_row4_col0, #T_26b47_row4_col1, #T_26b47_row4_col2, #T_26b47_row4_col3, #T_26b47_row5_col0, #T_26b47_row5_col1, #T_26b47_row5_col2, #T_26b47_row5_col3, #T_26b47_row6_col0, #T_26b47_row6_col1, #T_26b47_row6_col2, #T_26b47_row6_col3, #T_26b47_row7_col0, #T_26b47_row7_col1, #T_26b47_row7_col2, #T_26b47_row7_col3, #T_26b47_row8_col0, #T_26b47_row8_col1, #T_26b47_row8_col2, #T_26b47_row8_col3, #T_26b47_row9_col0, #T_26b47_row9_col1, #T_26b47_row9_col2, #T_26b47_row9_col3 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_26b47\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_26b47_level0_col0\" class=\"col_heading level0 col0\" >sentence</th>\n",
              "      <th id=\"T_26b47_level0_col1\" class=\"col_heading level0 col1\" >example_rating</th>\n",
              "      <th id=\"T_26b47_level0_col2\" class=\"col_heading level0 col2\" >pred_rating</th>\n",
              "      <th id=\"T_26b47_level0_col3\" class=\"col_heading level0 col3\" >exact_match_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_26b47_row0_col0\" class=\"data row0 col0\" >This is top tier.</td>\n",
              "      <td id=\"T_26b47_row0_col1\" class=\"data row0 col1\" >4</td>\n",
              "      <td id=\"T_26b47_row0_col2\" class=\"data row0 col2\" >4</td>\n",
              "      <td id=\"T_26b47_row0_col3\" class=\"data row0 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_26b47_row1_col0\" class=\"data row1 col0\" >Big mood.</td>\n",
              "      <td id=\"T_26b47_row1_col1\" class=\"data row1 col1\" >3</td>\n",
              "      <td id=\"T_26b47_row1_col2\" class=\"data row1 col2\" >3</td>\n",
              "      <td id=\"T_26b47_row1_col3\" class=\"data row1 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_26b47_row2_col0\" class=\"data row2 col0\" >The presentation was outstanding.</td>\n",
              "      <td id=\"T_26b47_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "      <td id=\"T_26b47_row2_col2\" class=\"data row2 col2\" >3</td>\n",
              "      <td id=\"T_26b47_row2_col3\" class=\"data row2 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_26b47_row3_col0\" class=\"data row3 col0\" >I'm living my best life.</td>\n",
              "      <td id=\"T_26b47_row3_col1\" class=\"data row3 col1\" >4</td>\n",
              "      <td id=\"T_26b47_row3_col2\" class=\"data row3 col2\" >4</td>\n",
              "      <td id=\"T_26b47_row3_col3\" class=\"data row3 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_26b47_row4_col0\" class=\"data row4 col0\" >Sksksksk, that's hilarious.</td>\n",
              "      <td id=\"T_26b47_row4_col1\" class=\"data row4 col1\" >3</td>\n",
              "      <td id=\"T_26b47_row4_col2\" class=\"data row4 col2\" >3</td>\n",
              "      <td id=\"T_26b47_row4_col3\" class=\"data row4 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_26b47_row5_col0\" class=\"data row5 col0\" >The report is comprehensive.</td>\n",
              "      <td id=\"T_26b47_row5_col1\" class=\"data row5 col1\" >1</td>\n",
              "      <td id=\"T_26b47_row5_col2\" class=\"data row5 col2\" >1</td>\n",
              "      <td id=\"T_26b47_row5_col3\" class=\"data row5 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_26b47_row6_col0\" class=\"data row6 col0\" >This is next level.</td>\n",
              "      <td id=\"T_26b47_row6_col1\" class=\"data row6 col1\" >4</td>\n",
              "      <td id=\"T_26b47_row6_col2\" class=\"data row6 col2\" >4</td>\n",
              "      <td id=\"T_26b47_row6_col3\" class=\"data row6 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_26b47_row7_col0\" class=\"data row7 col0\" >The meeting was productive.</td>\n",
              "      <td id=\"T_26b47_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "      <td id=\"T_26b47_row7_col2\" class=\"data row7 col2\" >1</td>\n",
              "      <td id=\"T_26b47_row7_col3\" class=\"data row7 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_26b47_row8_col0\" class=\"data row8 col0\" >The analysis was insightful.</td>\n",
              "      <td id=\"T_26b47_row8_col1\" class=\"data row8 col1\" >1</td>\n",
              "      <td id=\"T_26b47_row8_col2\" class=\"data row8 col2\" >2</td>\n",
              "      <td id=\"T_26b47_row8_col3\" class=\"data row8 col3\" ><class 'str'></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_26b47_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_26b47_row9_col0\" class=\"data row9 col0\" >I stan a legend.</td>\n",
              "      <td id=\"T_26b47_row9_col1\" class=\"data row9 col1\" >3</td>\n",
              "      <td id=\"T_26b47_row9_col2\" class=\"data row9 col2\" >3</td>\n",
              "      <td id=\"T_26b47_row9_col3\" class=\"data row9 col3\" >‚úîÔ∏è [True]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f50c5c84910>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_fewshot(compiled_dspy_BOOTSTRAP, metric=exact_match_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k9ov1j-pMV8"
      },
      "source": [
        "We can see that this optimization helps our program achieve 30 points higher on our evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-7qjXPKWMWF",
        "outputId": "b53cb50f-2dac-44d1-9b6d-732374516a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `sentence` (str)\n",
            "\n",
            "Your output fields are:\n",
            "1. `rating` (int): ${rating} (Respond with a single int value)\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "{sentence}\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "{rating}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        Rate a sentence from 0 to 4 on a dopeness scale\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This tea is piping hot.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "Your professionalism is appreciated.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I'm shook!\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "This is a whole mood.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The research was extensive.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "No cap, that's amazing.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I'm so here for this drama.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "3\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "The documentation is complete.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I can't even with this homework.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "3\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "Your feedback is valuable.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "1\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I'm hyped.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "Bless up!\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rating ## ]]\n",
            "4\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## sentence ## ]]\n",
            "I stan a legend.\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `rating`, and then ending with the marker for `completed`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## rating ## ]]\n",
            "3\n",
            "\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "llm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEP0Sf6CUvuo",
        "outputId": "c1c961c5-e375-491e-f8d1-10fa04f41bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter generate_rating.predictor: Num Examples: 12, Example({'augmented': True, 'sentence': 'This tea is piping hot.', 'rating': 4}) (input_keys=None)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, parameter in compiled_dspy_BOOTSTRAP.named_parameters():\n",
        "  print(f\"Parameter {name}: Num Examples: {len(parameter.demos)}, {parameter.demos[0]}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnKHiDch1H8O"
      },
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbRgUUYK-qbd"
      },
      "source": [
        "## Task 1: Defining Application\n",
        "\n",
        "In this breakoutroom, we'll be using DSPy to optimize a Multi-Hop QA module with `Assertions`.\n",
        "\n",
        "So what is a \"Multi-Hop QA module\"?\n",
        "\n",
        "Well - going beyond naive RAG retrieval, Multi-Hop QA lets us create applications that are well-suited to questions that (potentially have) multiple \"hops\" required to answer them.\n",
        "\n",
        "For instance: \"Who is the top goal scorer that has ever played on the Winnipeg Jets, and what years did he play for the Winnipeg Jets?\"\n",
        "\n",
        "You can see that there are two \"hops\" required to respond correctly:\n",
        "\n",
        "1. Who is the top goal scorer for the Winnipeg Jets?\n",
        "2. What years did X player play for the Winnipeg Jets?\n",
        "\n",
        "While this is a toy example, the idea is the same across complexity: Questions that take more than one step of reasoning to answer.\n",
        "\n",
        "Let's grab some data, set-up some hyper-parameters, and then get to implmentation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtLPLh-RAHgx"
      },
      "source": [
        "## Task 2: Hyper-Parameters and Data\n",
        "\n",
        "We'll use the DSPy ColBERT abstracts as our retrieval system for this example.\n",
        "\n",
        "We'll also use `GPT-4o-Mini` as our LM to keep things light and inexpensive as we'll be sending quite a few LLM calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TsZ_AUUg5HaL"
      },
      "outputs": [],
      "source": [
        "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
        "dspy.settings.configure(rm=colbertv2_wiki17_abstracts)\n",
        "lm_openai_four_mini = dspy.LM(model='openai/gpt-4o-mini', max_tokens=500)\n",
        "dspy.settings.configure(lm=lm_openai_four_mini, trace=[], temperature=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_36Kh9pbAZ7R"
      },
      "source": [
        "We'll be using the [`HotPotQA`](https://hotpotqa.github.io/) dataset which is a number of multi-hop QA pairs that includes context, and is based on Wikipedia (for compatibility with our Retriever system).\n",
        "\n",
        "- train_seed - random seed for sampling the training get\n",
        "- train_size - limit number of examples from training set\n",
        "- eval_seed - random seed for sampling the evaluation set\n",
        "- test_size - no test set provided\n",
        "- keep_details - additional details or metadata about dataset are/are not preserved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "ddc89690926542edb21e18d21b38f290",
            "c9a5e98ac1c0439184a25156faccafa4",
            "3cc62e51c0054391a97285041effb9eb",
            "157f2e32d4d64b0f97fce8dd6b6c0aa0",
            "e9f68cc27b0447edbf869c2b574561d3",
            "f582823133e742fd97c493b13ad6725a",
            "3fabea11413045bc855b15f67a19295b",
            "a6b6a55df9e54f4e8a78b60be2d6b428",
            "bfdd211fe3254acebc8055c64d860df4",
            "13a65abc2df041a883bbb5eed0e52b5f",
            "46706fe76314427dadc2ace6cd08298f",
            "cccb6cb145144b4dbc1193a3ad038da6",
            "ef9741e6c7294731a93322a729722a70",
            "7fe72ab9ede74cc99fe65d4661711878",
            "aa094cc9d2de43628f9c5d84e912cc28",
            "439d0a0aa2ee45a596ffb818f7e9aba7",
            "67d1745c64aa4b84ae3ee9af9913300d",
            "9c17831856c9468db0a509757dad7bab",
            "287f9d25fd2b4067ac2cceab564582ad",
            "b3a0943acee3465f8b8a17022e5377e4",
            "7e2b681cdc6a4bdc9fe8960f0716075b",
            "d21d239a8cd4400b9987c0d8f67e9e6a",
            "8095e6b1e63f435f8cca916f3e006ad6",
            "068bac62fba641dfbcbd5c3196ff7340",
            "a15e6f0872ef42b0b3dbb911d8230e38",
            "114148a5f6604d3b884979d817e0de14",
            "a44728f29e1a4ac1be943dea32b4f523",
            "53b4ac424fb64014ba31b3a2a23d115d",
            "d493a94b45e043cb9160bfa1c8551034",
            "0f19dcbac295409eb34c344398253185",
            "6b836b589fec4ebaaf87cf8e09231188",
            "99d0d381e9a04abfa13f7d77c545fd4e",
            "e4252456e5e64ffcb8b878cd8e91fccd",
            "04ed1e19a0804e43a57c24237d8bf39b",
            "40bce611191f458ea7cb46c377772aaf",
            "b2ee20a1a0304a53ad2fb0f255eaa238",
            "65d95352e3734b888baf328f43052059",
            "fa46867bccfa46a99776ef6860efcad5",
            "b6bda1a7494144b2a33f90d388904cb1",
            "7489ab1143944c04a43852be97abf167",
            "7602ef16a6cd47ea99437b7169309bf5",
            "c5074a2d505e4ec3bbdeda7fd102d136",
            "210d4c7b54194dde94b537fe4241121b",
            "b5470ceb8e7549e182922046553ebe14",
            "ea13eefe1e5146c1b0efaf6daea9836d",
            "a73e7ea4421a48caaabee0d52dd9b587",
            "b3b02e6442fb404794e71927d1f51193",
            "bfff80779eec4b5892db0bffc21b51dc",
            "ef61094d96b947fbb6eae94525f26de4",
            "6a175e0b70904ad38ae51a34b1e45213",
            "aad65fcec3914434b3426c4642525fdb",
            "8368607ff6a245d28651cb836f69f4ce",
            "ea18f461695c46929f5e460171076f78",
            "67e6d1b2ee2c4848ab2d970eab619ba8",
            "332e15773ba849e19240cc8445fdb8a0",
            "9c6ef46097514ed9bbfd47bdda092428",
            "eaa63f930e1b42cab7f023a7269adbfd",
            "929627c2c12b494a970a680ba02afa13",
            "a1b4ff4c4a914ae8b5b9022ca62859fb",
            "18249fe85f49463591078ace65faadc6",
            "52076f7a4bac47cfb3a65c9757694908",
            "19ef5ad5902d43b38a2fce37391800ea",
            "0302a171e46b464abe17d81469b0594c",
            "28ee5df360274ac698d8b48462d70fe2",
            "957992fd850d4775ad9c54e41e77fdd8",
            "6bc764919f624e44b55a55fd6a3f8c4d",
            "4ebace7f52db461faf6e8f130bde035d",
            "0eea145cf3254a5c83ab0da961cf4def",
            "819092066aac4d7d8a5e51d56fb04539",
            "67fafbee75954a389a6d18b5b9fb1db4",
            "ba1fb3d2e0444db7aadd5e36d0ee3554",
            "aea86595dc1240df892fa61d2cb08b9f",
            "07ef69ac580e43f19cf1b5ce479e3a6d",
            "6f29c0d47e6e44428e7507bd2096d595",
            "ce41c10f3b084a3b8a85c4f5773204fe",
            "3f80665ab98b4c028258ce6f54cef756",
            "2918717a6b0c48a5b51f86ae538955b1",
            "b6222ce0ab55472c803f1e588b2094d1",
            "37aa6d1288f64fe48404a0225d057f90",
            "1b61b7277cfc4b93b00ae0d5e912672a",
            "18ec38fb829f489e9f70ec1a99b1ac8a",
            "6594989c3c784e1889bfab4936bf0202",
            "c8648d7df7aa4a788baf738a1b741d18",
            "7641e40416f44e628da9577cd185be33",
            "bfc1ab5a674b4f43bce5a2426be04fa3",
            "a7916b5cf83d478392c92d03d613ad0b",
            "04816968076446bd89d71a9133c889b8",
            "7a1ddbc8d17e47ec9686dba8c11a50da"
          ]
        },
        "id": "eHlnHiJD31G_",
        "outputId": "19897c4c-fb85-4315-b181-4373f952473c"
      },
      "outputs": [],
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0, keep_details=True)\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiBIhbwCA26F"
      },
      "source": [
        "We can look at a few examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLYSTfNh47I6",
        "outputId": "aeed7294-e288-497a-8231-0324172608c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: At My Window was released by which American singer-songwriter?\n",
            "Answer: John Townes Van Zandt\n",
            "Relevant Wikipedia Titles: {'Townes Van Zandt', 'At My Window (album)'}\n"
          ]
        }
      ],
      "source": [
        "train_example = trainset[0]\n",
        "print(f\"Question: {train_example.question}\")\n",
        "print(f\"Answer: {train_example.answer}\")\n",
        "print(f\"Relevant Wikipedia Titles: {train_example.gold_titles}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLQTYBXY48Gx",
        "outputId": "b76ae68f-6453-4041-a932-962166a1a746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
            "Answer: English\n",
            "Relevant Wikipedia Titles: {'Restaurant: Impossible', 'Robert Irvine'}\n"
          ]
        }
      ],
      "source": [
        "dev_example = devset[18]\n",
        "print(f\"Question: {dev_example.question}\")\n",
        "print(f\"Answer: {dev_example.answer}\")\n",
        "print(f\"Relevant Wikipedia Titles: {dev_example.gold_titles}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EINXkiD4A4-e"
      },
      "source": [
        "## Task 3: Signature and Module Creation\n",
        "\n",
        "As we learned above - the bread and butter for DSPy is the `Signature` and `Module`, so we'll create each below.\n",
        "\n",
        "For our `Signatures`, things are fairly straight-forward, we need to:\n",
        "\n",
        "1. Create a `Signature` that will allow us to generate sub-questions.\n",
        "2. Create a `Signature` that will provide citations for our responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "QozzQ2YnBErb"
      },
      "outputs": [],
      "source": [
        "from dsp.utils import deduplicate\n",
        "\n",
        "class GenerateSearchQuery(dspy.Signature):\n",
        "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    query = dspy.OutputField()\n",
        "\n",
        "class GenerateCitedParagraph(dspy.Signature):\n",
        "    \"\"\"Generate a paragraph with citations.\"\"\"\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    paragraph = dspy.OutputField(desc=\"includes citations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vktUyOnOBUxf"
      },
      "source": [
        "Our `Module` is a bit more complex than what we've seen before - so let's walk through what's happening inside of it. We're going to concern ourselves with the `forward` method - as that is where the logic of our `Module` is contained.\n",
        "\n",
        "In the `forward` method we:\n",
        "\n",
        "1. Create an empty list of contexts.\n",
        "2. For each `hop` in our `max_hops` (by default, it will be 2) we:\n",
        "  - Generate a new `query` using our `GenerateSearchQuery` with a `ChainOfThought` predictor.\n",
        "  - Retrieve a number (default 3) of `passages` based on that new `query`.\n",
        "  - Add unique (non-present) `passages` into our `context` list.\n",
        "3. Take all that `context` and our original `question` and generate a cited paragraph and use it to predict an answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5yLb4hAY4_ti"
      },
      "outputs": [],
      "source": [
        "class LongFormQA(dspy.Module):\n",
        "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
        "        super().__init__()\n",
        "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
        "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
        "        self.generate_cited_paragraph = dspy.ChainOfThought(GenerateCitedParagraph)\n",
        "        self.max_hops = max_hops\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = []\n",
        "        for hop in range(self.max_hops):\n",
        "            query = self.generate_query[hop](context=context, question=question).query\n",
        "            passages = self.retrieve(query).passages\n",
        "            context = deduplicate(context + passages)\n",
        "        pred = self.generate_cited_paragraph(context=context, question=question)\n",
        "        pred = dspy.Prediction(context=context, paragraph=pred.paragraph)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgY7ZP43CmIg"
      },
      "source": [
        "Next, we'll need a way to evaluate how we're doing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gReqGYZCuE9"
      },
      "source": [
        "## Task 4: Evaluating our LongFormQA Module.\n",
        "\n",
        "Now we'd like to evaluate our module - we'll need a number of helper functions to do so - which will be instantiated below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbQ26BmM5M-a"
      },
      "source": [
        "#### Utility Functions for Citation Checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeYo6sTX5NiZ",
        "outputId": "181ad9e7-f39d-4c33-8b72-94f3ccfcebac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/rchrdgwr/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import regex as re\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extract_text_by_citation(paragraph):\n",
        "    # extracts text chunks and associates it with the citation number\n",
        "    citation_regex = re.compile(r'(.*?)(\\[\\d+\\]\\.)', re.DOTALL)\n",
        "    parts_with_citation = citation_regex.findall(paragraph)\n",
        "    citation_dict = {}\n",
        "    for part, citation in parts_with_citation:\n",
        "        part = part.strip()\n",
        "        citation_num = re.search(r'\\[(\\d+)\\]\\.', citation).group(1)\n",
        "        citation_dict.setdefault(str(int(citation_num) - 1), []).append(part)\n",
        "    return citation_dict\n",
        "\n",
        "def correct_citation_format(paragraph):\n",
        "    # validates a paragraphs citation is correct format - citations are associated with proper sentences\n",
        "    modified_sentences = []\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    for sentence in sentences:\n",
        "        modified_sentences.append(sentence)\n",
        "    citation_regex = re.compile(r'\\[\\d+\\]\\.')\n",
        "    i = 0\n",
        "    if len(modified_sentences) == 1:\n",
        "      has_citation = bool(citation_regex.search(modified_sentences[i]))\n",
        "    while i < len(modified_sentences):\n",
        "      if len(modified_sentences[i:i+2]) == 2:\n",
        "        sentence_group = \" \".join(modified_sentences[i:i+2])\n",
        "        has_citation = bool(citation_regex.search(sentence_group))\n",
        "        if not has_citation:\n",
        "            return False\n",
        "        i += 2 if has_citation and i+1 < len(modified_sentences) and citation_regex.search(modified_sentences[i+1]) else 1\n",
        "      else:\n",
        "        return True\n",
        "    return True\n",
        "\n",
        "def has_citations(paragraph):\n",
        "    # checks for citations in the paragraph e.g., [1]., [2].) \n",
        "    return bool(re.search(r'\\[\\d+\\]\\.', paragraph))\n",
        "\n",
        "def citations_check(paragraph):\n",
        "    # combines checks that it has citations and they are valid format\n",
        "    return has_citations(paragraph) and correct_citation_format(paragraph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-odXQWg5WWD"
      },
      "source": [
        "### Checking Citation Faithfulness\n",
        "\n",
        "We will create a number of useful metrics for our pipeline - included \"Faithfulness\", as well as a number of more traditional metrics. \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TU5Yx0gE5C1c"
      },
      "outputs": [],
      "source": [
        "class CheckCitationFaithfulness(dspy.Signature):\n",
        "    # check cited text is based on the provided context \n",
        "    \"\"\"Verify that the text is based on the provided context.\"\"\"\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    text = dspy.InputField(desc=\"between 1 to 2 sentences\")\n",
        "    faithfulness = dspy.OutputField(desc=\"boolean indicating if text is faithful to context\")\n",
        "\n",
        "def citation_faithfulness(example, pred, trace):\n",
        "    paragraph, context = pred.paragraph, pred.context\n",
        "    citation_dict = extract_text_by_citation(paragraph)\n",
        "    if not citation_dict:\n",
        "        return False, None\n",
        "    context_dict = {str(i): context[i].split(' | ')[1] for i in range(len(context))}\n",
        "    faithfulness_results = []\n",
        "    unfaithful_citations = []\n",
        "    check_citation_faithfulness = dspy.ChainOfThought(CheckCitationFaithfulness)\n",
        "    for citation_num, texts in citation_dict.items():\n",
        "        if citation_num not in context_dict:\n",
        "            continue\n",
        "        current_context = context_dict[citation_num]\n",
        "        for text in texts:\n",
        "            try:\n",
        "                result = check_citation_faithfulness(context=current_context, text=text)\n",
        "                is_faithful = result.faithfulness.lower() == 'true'\n",
        "                faithfulness_results.append(is_faithful)\n",
        "                if not is_faithful:\n",
        "                    unfaithful_citations.append({'paragraph': paragraph, 'text': text, 'context': current_context})\n",
        "            except ValueError as e:\n",
        "                faithfulness_results.append(False)\n",
        "                unfaithful_citations.append({'paragraph': paragraph, 'text': text, 'error': str(e)})\n",
        "    final_faithfulness = all(faithfulness_results)\n",
        "    if not faithfulness_results:\n",
        "        return False, None\n",
        "    return final_faithfulness, unfaithful_citations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOinluoLDRXr"
      },
      "source": [
        "#### ‚ùìQuestion #2:\n",
        "\n",
        "How is faithfulness being determined here? How is this different from Ragas Faithfulness.\n",
        "\n",
        "\n",
        "#### ! Answer #2:\n",
        "\n",
        "The CheckCitationFaithfulness class defines the following:\n",
        "- context - input field - the source where citations are to be drawn\n",
        "- text - input field - the cited information\n",
        "- faithfulness - output field - boolean indication faithfulness - true/false\n",
        "\n",
        "The citation_faithfulness function is responsible for determining whether the text is faithful to the context provided ie the cited statement (or text) is based on facts or details found in the context. \n",
        "\n",
        "The process is as follows:\n",
        "- extract all citations from from the predicted paragraph - if none is found it is considered unfaithful\n",
        "- find all provided citations from the context\n",
        "- create a chain of thought predictor to check a citations faithfulness comparing the text and corresponding context\n",
        "- iterating over all citations in the context \n",
        "    - determine if the citation number is in the context\n",
        "    - use the COT predictor to determine if the text returned is based on the context\n",
        "    - if so record that it is faithful\n",
        "    - othewise log it to the unfaithful_citations\n",
        "- if all of the citations are faithful it is considered faithful\n",
        "\n",
        "In summary - this process validates that all of the text citations in the paragraph are faithful to the source context. It is a boolean and considered faithful or not. It is stricter than RAGAS and is used to ensure that cited information is properly represented\n",
        "\n",
        "In RAGAS, faithfulness is determined based on how accurately the generated test reflects the information from the context based on if the answer can be inferred from the given context. It is defined as a ratio:\n",
        "\n",
        "        Numclaims in answer that can be inferred from context / total num claims in the answer \n",
        "\n",
        "The RAGAS failthfulness is a range from 0 to 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1yA4kEbDbea"
      },
      "source": [
        "Next, we can create a number of useful metrics that rely on more traditional evaluations, like Precision, Recall, and \"does this contain the answer\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Cimjr9Ji5yY5"
      },
      "outputs": [],
      "source": [
        "from dsp.utils import normalize_text\n",
        "\n",
        "def extract_cited_titles_from_paragraph(paragraph, context):\n",
        "    cited_indices = [int(m.group(1)) for m in re.finditer(r'\\[(\\d+)\\]\\.', paragraph)]\n",
        "    cited_indices = [index - 1 for index in cited_indices if index <= len(context)]\n",
        "    cited_titles = [context[index].split(' | ')[0] for index in cited_indices]\n",
        "    return cited_titles\n",
        "\n",
        "def calculate_recall(example, pred, trace=None):\n",
        "    gold_titles = set(example['gold_titles'])\n",
        "    found_cited_titles = set(extract_cited_titles_from_paragraph(pred.paragraph, pred.context))\n",
        "    intersection = gold_titles.intersection(found_cited_titles)\n",
        "    recall = len(intersection) / len(gold_titles) if gold_titles else 0\n",
        "    return recall\n",
        "\n",
        "def calculate_precision(example, pred, trace=None):\n",
        "    gold_titles = set(example['gold_titles'])\n",
        "    found_cited_titles = set(extract_cited_titles_from_paragraph(pred.paragraph, pred.context))\n",
        "    intersection = gold_titles.intersection(found_cited_titles)\n",
        "    precision = len(intersection) / len(found_cited_titles) if found_cited_titles else 0\n",
        "    return precision\n",
        "\n",
        "def answer_correctness(example, pred, trace=None):\n",
        "    assert hasattr(example, 'answer'), \"Example does not have 'answer'.\"\n",
        "    normalized_context = normalize_text(pred.paragraph)\n",
        "    if isinstance(example.answer, str):\n",
        "        gold_answers = [example.answer]\n",
        "    elif isinstance(example.answer, list):\n",
        "        gold_answers = example.answer\n",
        "    else:\n",
        "        raise ValueError(\"'example.answer' is not string or list.\")\n",
        "    return 1 if any(normalize_text(answer) in normalized_context for answer in gold_answers) else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDdr3nY1D4Rb"
      },
      "source": [
        "### Creating the Evaluation Function\n",
        "\n",
        "In essence, all this function does is call all the created metrics above and sum/average them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "yiLjsf5050j9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate(module):\n",
        "    correctness_values = []\n",
        "    recall_values = []\n",
        "    precision_values = []\n",
        "    citation_faithfulness_values = []\n",
        "    for i in tqdm(range(len(devset[:20]))):\n",
        "        example = devset[i]\n",
        "        try:\n",
        "            pred = module(question=example.question)\n",
        "            correctness_values.append(answer_correctness(example, pred))\n",
        "            citation_faithfulness_score, _ = citation_faithfulness(None, pred, None)\n",
        "            citation_faithfulness_values.append(citation_faithfulness_score)\n",
        "            recall = calculate_recall(example, pred)\n",
        "            precision = calculate_precision(example, pred)\n",
        "            recall_values.append(recall)\n",
        "            precision_values.append(precision)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed generation with error: {e}\")\n",
        "\n",
        "    average_correctness = sum(correctness_values) / len(devset[:20]) if correctness_values else 0\n",
        "    average_recall = sum(recall_values) / len(devset[:20]) if recall_values else 0\n",
        "    average_precision = sum(precision_values) / len(devset[:20]) if precision_values else 0\n",
        "    average_citation_faithfulness = sum(citation_faithfulness_values) / len(devset[:20]) if citation_faithfulness_values else 0\n",
        "\n",
        "    print(f\"\\nAverage Correctness: {average_correctness}\")\n",
        "    print(f\"Average Recall: {average_recall}\")\n",
        "    print(f\"Average Precision: {average_precision}\")\n",
        "    print(f\"Average Citation Faithfulness: {average_citation_faithfulness}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9hqGVpaEXOi"
      },
      "source": [
        "### Evaluating our LongFormQA Module\n",
        "\n",
        "Finally, we can evaluate our module!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuHF8UQo52Qu",
        "outputId": "b7db8106-d495-45b2-9f4a-aa6c3aa7dc84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 125.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Correctness: 0.9\n",
            "Average Recall: 0.0\n",
            "Average Precision: 0.0\n",
            "Average Citation Faithfulness: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "longformqa = LongFormQA()\n",
        "evaluate(longformqa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3TKIZrGEh8p"
      },
      "source": [
        "This did surprisingly poorly on `Recall`, `Precision` and `Citation Faithfulness`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BMGNZSeEpfe"
      },
      "source": [
        "#### ‚ùìQuestion #3:\n",
        "\n",
        "Why did our `Module` do surprisingly poorly on `Recall`, `Precision` and `Citation Faithfulness`?\n",
        "\n",
        "> HINT: The name `LongFormQA` should provide a fairly big hint.\n",
        "\n",
        "#### ! Answer #3:\n",
        "\n",
        "LongFormQA is designed for longer, more detailed answers pulling data from multiple sources in this case using multi hop. This can cause additional content and hallucination. It  is more difficult to control than short precise answers. This leads to a drop in prceison and recall.\n",
        "\n",
        "The recall and precision are based on cited titles from the paragraphs and comparing them to the \"gold titles\" provided in the example. The cited titles could differ impacting precision and recall.\n",
        "\n",
        "Long form answers might paraphrase or add additional information which could make it harder to find exact match with the \"gold answer\".\n",
        "\n",
        "Recall - impacted by missing relevant titles or citations\n",
        "\n",
        "Precision - impacted by finding irrelevant or incorrect titles\n",
        "\n",
        "Answer correctness - impacted by longer, paraphrased response, introduction of variation and imprecision\n",
        "\n",
        "We also used a 0.7 temperature rating for the Lamguage Model which could introduce some randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX3rawv5E3xe"
      },
      "source": [
        "## Task 5: Adding `Assertions`.\n",
        "\n",
        "DSPy comes equipped with an extremely useful feature called `Assertions` and `Suggestions`.\n",
        "\n",
        "Let's take a look at what each one does:\n",
        "\n",
        "1. `dspy.Assert` - this is a hard rule that must be followed, and if it's not followed; an exception will be raised.\n",
        "2. `dspy.Suggest` - this is a looser rule, or guiding principle, it will not raise an exception if the rule isn't met; but it will try and ensure the suggestion is met.\n",
        "\n",
        "Let's improve our `Module` with some `dspy.Suggest`s!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "yAHRD9pm7Paa"
      },
      "outputs": [],
      "source": [
        "class LongFormQAWithAssertions(dspy.Module):\n",
        "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
        "        super().__init__()\n",
        "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
        "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
        "        self.generate_cited_paragraph = dspy.ChainOfThought(GenerateCitedParagraph)\n",
        "        self.max_hops = max_hops\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = []\n",
        "        for hop in range(self.max_hops):\n",
        "            query = self.generate_query[hop](context=context, question=question).query\n",
        "            passages = self.retrieve(query).passages\n",
        "            context = deduplicate(context + passages)\n",
        "        pred = self.generate_cited_paragraph(context=context, question=question)\n",
        "        pred = dspy.Prediction(context=context, paragraph=pred.paragraph)\n",
        "        dspy.Suggest(citations_check(pred.paragraph), \"Make sure every 1-2 sentences has citations. If any 1-2 sentences lack citations, add them in 'text... [x].' format.\", target_module=self.generate_cited_paragraph)\n",
        "        _, unfaithful_outputs = citation_faithfulness(None, pred, None)\n",
        "        if unfaithful_outputs:\n",
        "            unfaithful_pairs = [(output['text'], output['context']) for output in unfaithful_outputs]\n",
        "            for _, context in unfaithful_pairs:\n",
        "                dspy.Suggest(len(unfaithful_pairs) == 0, f\"Make sure your output is based on the following context: '{context}'.\", target_module=self.generate_cited_paragraph)\n",
        "        else:\n",
        "            return pred\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsnkEzZ_9Lkc"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Write out the above flow in natural language or using a drawing program.\n",
        "\n",
        "What is the key advantage provided by using `dspy.Suggest`?\n",
        "\n",
        "### Response #2:\n",
        "\n",
        "- Using multi-hop create the search queries and retrieve relevant passages based on the input question\n",
        "- create the paragraph with citations based on retrieved content\n",
        "- using dspy.suggest - check that there is a citation every 1-2 sentences - if not, add it \n",
        "- check the faithfulness of the generated text to the context\n",
        "- using dspy.suggest - change the response if unfaithful text is found to ensure it is based on the context\n",
        "\n",
        "\n",
        "Advantage of using dspy.suggest:\n",
        "- suggest provides guidance to improve the response based on checks for citation faithfulness\n",
        "- this encourages (not forces) the model to correct itself during the generation process\n",
        "- it verifies that each 1-2 sentences has a citation\n",
        "- if there is no citation, it suggests adding the citation\n",
        "- this ensures the created content adheres to the citation standards - resulting in better citation precision\n",
        "- for each unfaithful process, it is suggested that the text be recised based on the provided text. This helps remind the model to ensure the output aligns with the specific retrieved context. This should improve citation faithfulness\n",
        "\n",
        "The suggestions ensure:\n",
        "- citations are correctly placed every 1-2 sentences\n",
        "- correcting unfaithful outputs will reduce hallucinations and improve faithfulness\n",
        "\n",
        "Overall - dspy.Suggest can help the module improve by identifying weaknesses in the response and suggesting ways to improve "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBzJTpvq7RXW",
        "outputId": "609ac2bb-2f16-4ed1-ee58-f75ccbc2374d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [02:43<00:00,  8.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Correctness: 0.9\n",
            "Average Recall: 0.45\n",
            "Average Precision: 0.5416666666666666\n",
            "Average Citation Faithfulness: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dspy.primitives.assertions import assert_transform_module, backtrack_handler\n",
        "from dspy.predict import Retry\n",
        "\n",
        "longformqa_with_assertions = assert_transform_module(LongFormQAWithAssertions().map_named_predictors(Retry), backtrack_handler)\n",
        "evaluate(longformqa_with_assertions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up a few-shot learning process using BootstrapFewShotwithRandomSearch\n",
        "\n",
        "Use this to evaluate our LongFormQAWithAssertions\n",
        "\n",
        "BootstrapFewShotwithRandomSearch - bootstrap few shot learning with random search\n",
        "- select a few labeled examples and improve the performance by bootstrapping additional examples\n",
        "\n",
        "Compile the Student-Teacher model\n",
        "- Both student and teacher use instances of LongFormQAWithAssertions\n",
        "- This allos backtrack and retry predictions using the Retry predictor\n",
        "- The student model learns from the teacher models predictions\n",
        "- Teacher provides guidance and corrections to the student during training\n",
        "- Helps it learn to improve on generating long-form answers with proper citations and faithfulness\n",
        "\n",
        "Evaluate based on the valset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I8qm_Oq8bUo",
        "outputId": "4fa42a02-bbbb-4fe7-b38c-fa87914a24e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Going to sample between 1 and 2 traces per predictor.\n",
            "Will attempt to bootstrap 6 candidate sets.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 22 / 25  (88.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [01:23<00:00,  3.35s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best score: 88.0 for seed -3\n",
            "Scores so far: [88.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 22 / 25  (88.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 196.44it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|‚ñà‚ñà        | 4/20 [00:48<03:14, 12.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 5 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [04:32<00:00, 10.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|‚ñà         | 2/20 [00:23<03:27, 11.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 3 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [06:02<00:00, 14.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0, 76.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|‚ñå         | 1/20 [00:14<04:39, 14.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 18 / 25  (72.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [05:28<00:00, 13.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0, 76.0, 72.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|‚ñå         | 1/20 [00:16<05:17, 16.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 18 / 25  (72.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [05:44<00:00, 13.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0, 76.0, 72.0, 72.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|‚ñà         | 2/20 [00:11<01:39,  5.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 3 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [03:28<00:00,  8.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0, 76.0, 72.0, 72.0, 76.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|‚ñå         | 1/20 [00:13<04:11, 13.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [05:05<00:00, 12.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0, 76.0, 72.0, 72.0, 76.0, 80.0]\n",
            "Best score so far: 88.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|‚ñà‚ñå        | 3/20 [00:56<05:18, 18.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 4 examples in round 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [05:21<00:00, 12.84s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores so far: [88.0, 88.0, 80.0, 76.0, 72.0, 72.0, 76.0, 80.0, 76.0]\n",
            "Best score so far: 88.0\n",
            "9 candidate programs found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 218.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Correctness: 0.9\n",
            "Average Recall: 0.45\n",
            "Average Precision: 0.5416666666666666\n",
            "Average Citation Faithfulness: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
        "\n",
        "longformqa = LongFormQAWithAssertions()\n",
        "teleprompter = BootstrapFewShotWithRandomSearch(metric = answer_correctness, max_bootstrapped_demos=2, num_candidate_programs=6)\n",
        "cited_longformqa_student_teacher = teleprompter.compile(student=assert_transform_module(LongFormQAWithAssertions().map_named_predictors(Retry), backtrack_handler), teacher = assert_transform_module(LongFormQAWithAssertions().map_named_predictors(Retry), backtrack_handler), trainset=trainset, valset=devset[:25])\n",
        "evaluate(cited_longformqa_student_teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So ran for 40 minutes\n",
        "\n",
        "Best score was on first run\n",
        "\n",
        "No change in metrics \n",
        "\n",
        "Not sure what we accomplished here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KbQ26BmM5M-a"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0302a171e46b464abe17d81469b0594c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04816968076446bd89d71a9133c889b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ed1e19a0804e43a57c24237d8bf39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40bce611191f458ea7cb46c377772aaf",
              "IPY_MODEL_b2ee20a1a0304a53ad2fb0f255eaa238",
              "IPY_MODEL_65d95352e3734b888baf328f43052059"
            ],
            "layout": "IPY_MODEL_fa46867bccfa46a99776ef6860efcad5"
          }
        },
        "068bac62fba641dfbcbd5c3196ff7340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b4ac424fb64014ba31b3a2a23d115d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d493a94b45e043cb9160bfa1c8551034",
            "value": "Downloading‚Äádata:‚Äá100%"
          }
        },
        "07ef69ac580e43f19cf1b5ce479e3a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eea145cf3254a5c83ab0da961cf4def": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea86595dc1240df892fa61d2cb08b9f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_07ef69ac580e43f19cf1b5ce479e3a6d",
            "value": "Generating‚Äávalidation‚Äásplit:‚Äá100%"
          }
        },
        "0f19dcbac295409eb34c344398253185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114148a5f6604d3b884979d817e0de14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d0d381e9a04abfa13f7d77c545fd4e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e4252456e5e64ffcb8b878cd8e91fccd",
            "value": "‚Äá566M/566M‚Äá[00:14&lt;00:00,‚Äá51.1MB/s]"
          }
        },
        "13a65abc2df041a883bbb5eed0e52b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "157f2e32d4d64b0f97fce8dd6b6c0aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a65abc2df041a883bbb5eed0e52b5f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_46706fe76314427dadc2ace6cd08298f",
            "value": "‚Äá6.42k/6.42k‚Äá[00:00&lt;00:00,‚Äá290kB/s]"
          }
        },
        "18249fe85f49463591078ace65faadc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ec38fb829f489e9f70ec1a99b1ac8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04816968076446bd89d71a9133c889b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a1ddbc8d17e47ec9686dba8c11a50da",
            "value": "‚Äá7405/7405‚Äá[00:03&lt;00:00,‚Äá2089.20‚Äáexamples/s]"
          }
        },
        "19ef5ad5902d43b38a2fce37391800ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b61b7277cfc4b93b00ae0d5e912672a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc1ab5a674b4f43bce5a2426be04fa3",
            "max": 7405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7916b5cf83d478392c92d03d613ad0b",
            "value": 7405
          }
        },
        "210d4c7b54194dde94b537fe4241121b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287f9d25fd2b4067ac2cceab564582ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ee5df360274ac698d8b48462d70fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2918717a6b0c48a5b51f86ae538955b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "332e15773ba849e19240cc8445fdb8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37aa6d1288f64fe48404a0225d057f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8648d7df7aa4a788baf738a1b741d18",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7641e40416f44e628da9577cd185be33",
            "value": "Generating‚Äátest‚Äásplit:‚Äá100%"
          }
        },
        "3cc62e51c0054391a97285041effb9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b6a55df9e54f4e8a78b60be2d6b428",
            "max": 6422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfdd211fe3254acebc8055c64d860df4",
            "value": 6422
          }
        },
        "3f80665ab98b4c028258ce6f54cef756": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fabea11413045bc855b15f67a19295b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40bce611191f458ea7cb46c377772aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6bda1a7494144b2a33f90d388904cb1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7489ab1143944c04a43852be97abf167",
            "value": "Downloading‚Äádata:‚Äá100%"
          }
        },
        "439d0a0aa2ee45a596ffb818f7e9aba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46706fe76314427dadc2ace6cd08298f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ebace7f52db461faf6e8f130bde035d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eea145cf3254a5c83ab0da961cf4def",
              "IPY_MODEL_819092066aac4d7d8a5e51d56fb04539",
              "IPY_MODEL_67fafbee75954a389a6d18b5b9fb1db4"
            ],
            "layout": "IPY_MODEL_ba1fb3d2e0444db7aadd5e36d0ee3554"
          }
        },
        "52076f7a4bac47cfb3a65c9757694908": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b4ac424fb64014ba31b3a2a23d115d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6594989c3c784e1889bfab4936bf0202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d95352e3734b888baf328f43052059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210d4c7b54194dde94b537fe4241121b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b5470ceb8e7549e182922046553ebe14",
            "value": "‚Äá47.5M/47.5M‚Äá[00:00&lt;00:00,‚Äá46.5MB/s]"
          }
        },
        "67d1745c64aa4b84ae3ee9af9913300d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e6d1b2ee2c4848ab2d970eab619ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67fafbee75954a389a6d18b5b9fb1db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f80665ab98b4c028258ce6f54cef756",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2918717a6b0c48a5b51f86ae538955b1",
            "value": "‚Äá7405/7405‚Äá[00:03&lt;00:00,‚Äá2789.89‚Äáexamples/s]"
          }
        },
        "6a175e0b70904ad38ae51a34b1e45213": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b836b589fec4ebaaf87cf8e09231188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bc764919f624e44b55a55fd6a3f8c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f29c0d47e6e44428e7507bd2096d595": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7489ab1143944c04a43852be97abf167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7602ef16a6cd47ea99437b7169309bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7641e40416f44e628da9577cd185be33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a1ddbc8d17e47ec9686dba8c11a50da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e2b681cdc6a4bdc9fe8960f0716075b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe72ab9ede74cc99fe65d4661711878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287f9d25fd2b4067ac2cceab564582ad",
            "max": 9193,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3a0943acee3465f8b8a17022e5377e4",
            "value": 9193
          }
        },
        "8095e6b1e63f435f8cca916f3e006ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_068bac62fba641dfbcbd5c3196ff7340",
              "IPY_MODEL_a15e6f0872ef42b0b3dbb911d8230e38",
              "IPY_MODEL_114148a5f6604d3b884979d817e0de14"
            ],
            "layout": "IPY_MODEL_a44728f29e1a4ac1be943dea32b4f523"
          }
        },
        "819092066aac4d7d8a5e51d56fb04539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f29c0d47e6e44428e7507bd2096d595",
            "max": 7405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce41c10f3b084a3b8a85c4f5773204fe",
            "value": 7405
          }
        },
        "8368607ff6a245d28651cb836f69f4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929627c2c12b494a970a680ba02afa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0302a171e46b464abe17d81469b0594c",
            "max": 90447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28ee5df360274ac698d8b48462d70fe2",
            "value": 90447
          }
        },
        "957992fd850d4775ad9c54e41e77fdd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d0d381e9a04abfa13f7d77c545fd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c17831856c9468db0a509757dad7bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c6ef46097514ed9bbfd47bdda092428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaa63f930e1b42cab7f023a7269adbfd",
              "IPY_MODEL_929627c2c12b494a970a680ba02afa13",
              "IPY_MODEL_a1b4ff4c4a914ae8b5b9022ca62859fb"
            ],
            "layout": "IPY_MODEL_18249fe85f49463591078ace65faadc6"
          }
        },
        "a15e6f0872ef42b0b3dbb911d8230e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f19dcbac295409eb34c344398253185",
            "max": 566426227,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b836b589fec4ebaaf87cf8e09231188",
            "value": 566426227
          }
        },
        "a1b4ff4c4a914ae8b5b9022ca62859fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_957992fd850d4775ad9c54e41e77fdd8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6bc764919f624e44b55a55fd6a3f8c4d",
            "value": "‚Äá90447/90447‚Äá[00:54&lt;00:00,‚Äá3076.72‚Äáexamples/s]"
          }
        },
        "a44728f29e1a4ac1be943dea32b4f523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b6a55df9e54f4e8a78b60be2d6b428": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73e7ea4421a48caaabee0d52dd9b587": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a175e0b70904ad38ae51a34b1e45213",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aad65fcec3914434b3426c4642525fdb",
            "value": "Downloading‚Äádata:‚Äá100%"
          }
        },
        "a7916b5cf83d478392c92d03d613ad0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa094cc9d2de43628f9c5d84e912cc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2b681cdc6a4bdc9fe8960f0716075b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d21d239a8cd4400b9987c0d8f67e9e6a",
            "value": "‚Äá9.19k/9.19k‚Äá[00:00&lt;00:00,‚Äá322kB/s]"
          }
        },
        "aad65fcec3914434b3426c4642525fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aea86595dc1240df892fa61d2cb08b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ee20a1a0304a53ad2fb0f255eaa238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7602ef16a6cd47ea99437b7169309bf5",
            "max": 47454698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5074a2d505e4ec3bbdeda7fd102d136",
            "value": 47454698
          }
        },
        "b3a0943acee3465f8b8a17022e5377e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3b02e6442fb404794e71927d1f51193": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8368607ff6a245d28651cb836f69f4ce",
            "max": 46213747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea18f461695c46929f5e460171076f78",
            "value": 46213747
          }
        },
        "b5470ceb8e7549e182922046553ebe14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6222ce0ab55472c803f1e588b2094d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37aa6d1288f64fe48404a0225d057f90",
              "IPY_MODEL_1b61b7277cfc4b93b00ae0d5e912672a",
              "IPY_MODEL_18ec38fb829f489e9f70ec1a99b1ac8a"
            ],
            "layout": "IPY_MODEL_6594989c3c784e1889bfab4936bf0202"
          }
        },
        "b6bda1a7494144b2a33f90d388904cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1fb3d2e0444db7aadd5e36d0ee3554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc1ab5a674b4f43bce5a2426be04fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdd211fe3254acebc8055c64d860df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfff80779eec4b5892db0bffc21b51dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e6d1b2ee2c4848ab2d970eab619ba8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_332e15773ba849e19240cc8445fdb8a0",
            "value": "‚Äá46.2M/46.2M‚Äá[00:01&lt;00:00,‚Äá48.1MB/s]"
          }
        },
        "c5074a2d505e4ec3bbdeda7fd102d136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8648d7df7aa4a788baf738a1b741d18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a5e98ac1c0439184a25156faccafa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f582823133e742fd97c493b13ad6725a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3fabea11413045bc855b15f67a19295b",
            "value": "hotpot_qa.py:‚Äá100%"
          }
        },
        "cccb6cb145144b4dbc1193a3ad038da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef9741e6c7294731a93322a729722a70",
              "IPY_MODEL_7fe72ab9ede74cc99fe65d4661711878",
              "IPY_MODEL_aa094cc9d2de43628f9c5d84e912cc28"
            ],
            "layout": "IPY_MODEL_439d0a0aa2ee45a596ffb818f7e9aba7"
          }
        },
        "ce41c10f3b084a3b8a85c4f5773204fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d21d239a8cd4400b9987c0d8f67e9e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d493a94b45e043cb9160bfa1c8551034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddc89690926542edb21e18d21b38f290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9a5e98ac1c0439184a25156faccafa4",
              "IPY_MODEL_3cc62e51c0054391a97285041effb9eb",
              "IPY_MODEL_157f2e32d4d64b0f97fce8dd6b6c0aa0"
            ],
            "layout": "IPY_MODEL_e9f68cc27b0447edbf869c2b574561d3"
          }
        },
        "e4252456e5e64ffcb8b878cd8e91fccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9f68cc27b0447edbf869c2b574561d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea13eefe1e5146c1b0efaf6daea9836d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73e7ea4421a48caaabee0d52dd9b587",
              "IPY_MODEL_b3b02e6442fb404794e71927d1f51193",
              "IPY_MODEL_bfff80779eec4b5892db0bffc21b51dc"
            ],
            "layout": "IPY_MODEL_ef61094d96b947fbb6eae94525f26de4"
          }
        },
        "ea18f461695c46929f5e460171076f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaa63f930e1b42cab7f023a7269adbfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52076f7a4bac47cfb3a65c9757694908",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_19ef5ad5902d43b38a2fce37391800ea",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "ef61094d96b947fbb6eae94525f26de4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9741e6c7294731a93322a729722a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d1745c64aa4b84ae3ee9af9913300d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9c17831856c9468db0a509757dad7bab",
            "value": "README.md:‚Äá100%"
          }
        },
        "f582823133e742fd97c493b13ad6725a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa46867bccfa46a99776ef6860efcad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
